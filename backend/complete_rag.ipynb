{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Dp6rXsG7bjwz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vietlong/Documents/DATN/backend/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/vietlong/Documents/DATN/backend/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/vietlong/Documents/DATN/backend/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.packs.raft_dataset import RAFTDatasetPack\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import ServiceContext, set_global_service_context, Settings\n",
    "\n",
    "from transformers import (\n",
    "  # AutoTokenizer,\n",
    "  AutoModelForCausalLM,\n",
    "  BitsAndBytesConfig,\n",
    "  pipeline,\n",
    ")\n",
    "import psycopg2\n",
    "from sqlalchemy import make_url\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "# import wandb\n",
    "from sqlalchemy import create_engine, text\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "from llama_index.core.node_parser import MarkdownNodeParser #, MarkdownElementNodeParser\n",
    "# from llama_index.core import SimpleDirectoryReader\n",
    "# from llama_index.core.node_parser import SimpleFileNodeParser\n",
    "from llama_index.readers.file import FlatReader\n",
    "from pathlib import Path\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, load_index_from_storage, load_indices_from_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJR8t08KyhWW"
   },
   "source": [
    "# Load llm and embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kJWvHyRpmi0v"
   },
   "outputs": [],
   "source": [
    "embedding_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "llm_name = \"models/llms/vietcuna-3b-v2\"\n",
    "# llm_name = \"vilm/vietcuna-3b-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"models/embedding_model/mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdHpAvfYegi8"
   },
   "outputs": [],
   "source": [
    "def load_embedding_model(model_name: str):\n",
    "  return HuggingFaceEmbedding(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hf3_vYd9j6_E"
   },
   "outputs": [],
   "source": [
    "def load_llm(model_name: str) -> HuggingFaceLLM:\n",
    "  # Kích hoạt mô hình cơ sở độ chính xác 4 bit đang tải\n",
    "  # use_4bit = True\n",
    "\n",
    "  # # Tính toán kiểu dữ liệu cho các mô hình cơ sở 4 bit\n",
    "  # bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "  # # Kiểu lượng tử hóa (fp4 hoặc nf4)\n",
    "  # bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "  # # Kích hoạt lượng tử hóa lồng nhau cho cơ sở 4 bit mô hình (lượng tử hóa kép)\n",
    "  # use_nested_quant = False\n",
    "\n",
    "  # compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "  # bnb_config = BitsAndBytesConfig(\n",
    "  # load_in_4bit=use_4bit,\n",
    "  # bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "  # bnb_4bit_compute_dtype=compute_dtype,\n",
    "  # bnb_4bit_use_double_quant=use_nested_quant,\n",
    "  # )\n",
    "  llm = HuggingFaceLLM(model_name=model_name,\n",
    "                       tokenizer_name=model_name,\n",
    "                      #  model_kwargs={\"quantization_config\": bnb_config},\n",
    "                       device_map=\"cuda\")\n",
    "\n",
    "  return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'models/llms/vietcuna-3b-v2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'models/llms/vietcuna-3b-v2' is the correct path to a directory containing all relevant files for a BloomTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mload_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mload_llm\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_llm\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HuggingFaceLLM:\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Kích hoạt mô hình cơ sở độ chính xác 4 bit đang tải\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# use_4bit = True\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[38;5;66;03m# bnb_4bit_use_double_quant=use_nested_quant,\u001b[39;00m\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m   llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m#  model_kwargs={\"quantization_config\": bnb_config},\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/llama_index/llms/huggingface/base.py:258\u001b[0m, in \u001b[0;36mHuggingFaceLLM.__init__\u001b[0;34m(self, context_window, max_new_tokens, query_wrapper_prompt, tokenizer_name, model_name, model, tokenizer, device_map, stopping_ids, tokenizer_kwargs, tokenizer_outputs_to_remove, model_kwargs, generate_kwargs, is_chat_model, callback_manager, system_prompt, messages_to_prompt, completion_to_prompt, pydantic_program_mode, output_parser)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_kwargs:\n\u001b[1;32m    256\u001b[0m     tokenizer_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context_window\n\u001b[0;32m--> 258\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tokenizer \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mname_or_path \u001b[38;5;241m!=\u001b[39m model\u001b[38;5;241m.\u001b[39mname_or_path:\n\u001b[1;32m    263\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` and tokenizer `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer\u001b[38;5;241m.\u001b[39mname_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare different, please ensure that they are compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:939\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2197\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2198\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2202\u001b[0m     )\n\u001b[1;32m   2204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'models/llms/vietcuna-3b-v2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'models/llms/vietcuna-3b-v2' is the correct path to a directory containing all relevant files for a BloomTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "llm = load_llm(model_name=llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 11.00 MiB is free. Including non-PyTorch memory, this process has 3.79 GiB memory in use. Of the allocated memory 3.62 GiB is allocated by PyTorch, and 114.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m compute_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch, bnb_4bit_compute_dtype)\n\u001b[1;32m     14\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(load_in_4bit\u001b[38;5;241m=\u001b[39muse_4bit,\n\u001b[1;32m     15\u001b[0m bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39mbnb_4bit_quant_type,\n\u001b[1;32m     16\u001b[0m bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mcompute_dtype,\n\u001b[1;32m     17\u001b[0m bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39muse_nested_quant,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:4728\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4724\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4725\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4726\u001b[0m                 )\n\u001b[1;32m   4727\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4728\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4734\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4735\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4742\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4744\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4746\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:995\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    993\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 995\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:238\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.create_quantized_param\u001b[0;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[1;32m    235\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    237\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 238\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:332\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_quantized:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/DATN/backend/.venv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:296\u001b[0m, in \u001b[0;36mParams4bit._quantize\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[0;32m--> 296\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     w_4bit, quant_state \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mquantize_4bit(\n\u001b[1;32m    298\u001b[0m         w,\n\u001b[1;32m    299\u001b[0m         blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m         quant_storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_storage,\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m w_4bit\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 11.00 MiB is free. Including non-PyTorch memory, this process has 3.79 GiB memory in use. Of the allocated memory 3.62 GiB is allocated by PyTorch, and 114.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# # Kích hoạt mô hình cơ sở độ chính xác 4 bit đang tải\n",
    "# use_4bit = True\n",
    "\n",
    "# # Tính toán kiểu dữ liệu cho các mô hình cơ sở 4 bit\n",
    "# bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# # Kiểu lượng tử hóa (fp4 hoặc nf4)\n",
    "# bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# # Kích hoạt lượng tử hóa lồng nhau cho cơ sở 4 bit mô hình (lượng tử hóa kép)\n",
    "# use_nested_quant = False\n",
    "\n",
    "# compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "# bnb_config = BitsAndBytesConfig(load_in_4bit=use_4bit,\n",
    "# bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "# bnb_4bit_compute_dtype=compute_dtype,\n",
    "# bnb_4bit_use_double_quant=use_nested_quant,\n",
    "# )\n",
    "\n",
    "# llm = AutoModelForCausalLM.from_pretrained(llm_name, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQbSLQWWuqVn"
   },
   "source": [
    "# Node parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y6cOY98TvrpF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = FlatReader().load_data(Path(\"data/sotay.md\"))\n",
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgresql://postgres:smileup@localhost:5432\"\n",
    "db_name = \"vector_db\"\n",
    "conn = psycopg2.connect(connection_string)\n",
    "conn.autocommit = True\n",
    "\n",
    "# with conn.cursor() as c:\n",
    "#     c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "#     c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = make_url(connection_string)\n",
    "db_params = {\n",
    "    \"user\": url.username,      # Replace with your actual username\n",
    "    \"password\": url.password,  # Replace with your actual password\n",
    "    \"host\": url.host,   # Adjust if your database is hosted elsewhere\n",
    "    \"port\": url.port,        # Default PostgreSQL port\n",
    "    \"database\": \"vector_db\",  # Replace with your actual database name\n",
    "    \"schema_name\": \"rag\",\n",
    "    \"embed_dim\": 768,\n",
    "    \"table_name\": \"sotaysinhvien\"\n",
    "}\n",
    "table_name = \"data_sotaysinhvien\"\n",
    "embed_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema 'rag' does not exist. Creating it...\n",
      "init\n",
      "result: None\n",
      "schema created True\n",
      "Schema 'rag' and table 'data_sotaysinhvien' has been created.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\")\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # check if the schema exists\n",
    "        result = conn.execute(text(f\"\"\"\n",
    "                SELECT EXISTS (\n",
    "                    SELECT FROM information_schema.tables\n",
    "                    WHERE table_schema = :schema_name\n",
    "            );\n",
    "            \"\"\"), {\"schema_name\": db_params[\"schema_name\"]}).scalar()\n",
    "        if result:\n",
    "            print(f\"Schema '{db_params['schema_name']}' exist, skipping creating table.\\n Recreating the schema to create the table'\")\n",
    "            conn.execute(text(f\"DROP SCHEMA IF EXISTS {db_params['schema_name']} CASCADE;\"))\n",
    "        else:\n",
    "            print(f\"Schema '{db_params['schema_name']}' does not exist. Creating it...\")\n",
    "\n",
    "        # # Check if the table exists\n",
    "        # result = conn.execute(text(f\"\"\"\n",
    "        #     SELECT EXISTS (\n",
    "        #         SELECT FROM information_schema.tables \n",
    "        #         WHERE table_schema = :schema_name AND table_name = :table_name\n",
    "        #     );\n",
    "        # \"\"\"), {\"table_name\": table_name, \"schema_name\": db_params[\"schema\"]}).scalar()\n",
    "        # print(result)\n",
    "        # if result:\n",
    "        #     print(f\"Table '{table_name}' exists. Cleaning it...\")\n",
    "        #     conn.execute(text(f\"TRUNCATE TABLE {table_name};\"))\n",
    "        # else:\n",
    "        #     print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "\n",
    "        # Create a new table for vector store\n",
    "        vector_store = PGVectorStore.from_params(\n",
    "            database=db_params[\"database\"],\n",
    "            host=db_params[\"host\"],\n",
    "            password=db_params[\"password\"],\n",
    "            port=db_params[\"port\"],\n",
    "            user=db_params[\"user\"],\n",
    "            table_name=db_params[\"table_name\"],  # Use unprefixed name; PGVectorStore adds 'data_' automatically\n",
    "            embed_dim=db_params[\"embed_dim\"],\n",
    "            schema_name=db_params[\"schema_name\"]\n",
    "        )\n",
    "        vector_store._initialize()\n",
    "        print(f\"Schema '{db_params['schema_name']}' and table '{table_name}' has been created.\")\n",
    "except OperationalError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure the database exists and connection parameters are correr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVectorStore.from_params(\n",
    "            database=db_params[\"database\"],\n",
    "            host=db_params[\"host\"],\n",
    "            password=db_params[\"password\"],\n",
    "            port=db_params[\"port\"],\n",
    "            user=db_params[\"user\"],\n",
    "            table_name=db_params[\"table_name\"],  # Use unprefixed name; PGVectorStore adds 'data_' automatically\n",
    "            embed_dim=db_params[\"embed_dim\"],\n",
    "            schema_name=db_params[\"schema_name\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"storage_context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir=persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "result: ('rag',)\n",
      "schema created False\n"
     ]
    }
   ],
   "source": [
    "storage_context.docstore.add_documents(documents)\n",
    "index = VectorStoreIndex.from_documents(documents=documents,\n",
    "                                        storage_context=storage_context,\n",
    "                                        transformations=[MarkdownNodeParser()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_to_json = {\"sotaysinhvien\": str(uuid4())}\n",
    "# with open(\"doc_to_id.json\", \"a+\") as f: \n",
    "#     json.dump(doc_to_json, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sotaysinhvien': '17a14fb1-86e9-4d39-9e66-856caaf97d08'}\n"
     ]
    }
   ],
   "source": [
    "with open('doc_to_id.json', 'r') as f:\n",
    "    doc_to_json = json.load(f)\n",
    "\n",
    "print(doc_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_index_from_storage(storage_context=storage_context, index_id=doc_to_json['sotaysinhvien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVIamnkN6DsP"
   },
   "outputs": [],
   "source": [
    "answer = index.as_query_engine().query(\"Các câu lạc bộ trường đại học PHENIKAA bao gồm các câu lạc bộ nào?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1732200968259,
     "user": {
      "displayName": "Việt Long Nguyễn",
      "userId": "09059401133377870555"
     },
     "user_tz": -420
    },
    "id": "vnuhVNND6G_F",
    "outputId": "239fe1ba-9291-4ea8-8847-8ea81dc2ae6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Các câu lạc bộ trường đại học PHENIKAA bao gồm các câu lạc bộ sau:\\n\\n 1. Câu lạc bộ sinh viên học thuật:\\n - CLB Lý Luận Trẻ\\n - CLB Lãnh đạo trẻ\\n - CLB Marketing\\n - CLB Kế toán\\n - CLB Luật Kinh tế\\n - CLB Một Sức Khoẻ\\n - CLB Nghiên cứu khoa học Khoa Dược\\n - CLB Sinh viên Kỹ thuật\\n - CLB Tài Chính & Kinh doanh\\n - CLB Tiếng Anh\\n - CLB tiếng Trung Quốc\\n - CLB Khởi nghiệp Sáng tạo\\n - CLB Nhân Lực\\n - CLB Sinh viên Điều dưỡng\\n - CLB Y Học\\n - CLB Kinh doanh Quốc tế\\n - CLB Tiếng Anh\\n - CLB tiếng Trung Quốc\\n - CLB Khởi nghiệp Sáng tạo\\n - CLB Nhân Lực\\n - CLB Sinh viên Điều dưỡng\\n - CLB Y Học\\n - CLB Kinh doanh Quốc tế\\n - CLB Tiếng Anh\\n - CLB tiếng Trung Quốc\\n - CLB Khởi nghiệp Sáng tạo\\n - CLB Nhân Lực\\n - CLB Sinh viên Điều dưỡng\\n - CLB Y Học\\n - CLB Kinh doanh Quốc tế\\n - CLB Tiếng Anh\\n - CLB tiếng Trung Quốc\\n - CLB Khởi nghiệp Sáng tạo\\n - CLB Nhân Lực\\n - CLB Sinh viên Điều dưỡng\\n - CLB Y Học\\n', source_nodes=[NodeWithScore(node=TextNode(id_='56762154-7c55-485a-8bd2-a89d3c77372b', embedding=None, metadata={'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='80ae3218-f083-48a4-aff9-c3e81e4fd2a9', node_type='4', metadata={'filename': 'sotay.md', 'extension': '.md'}, hash='435de79ca1d20618b2c86e11a7573a678269e32b107969df99a709e89da8ea19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='904e66c6-8aff-431d-a714-a4c707162449', node_type='1', metadata={'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, hash='8ed54e54728ffe3825e13f5a8fa2fea922fcfb3c7320a9a2143c7eabf5b9fee6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1b0b4b1c-f2b2-4d32-b3e0-e8d294d839f7', node_type='1', metadata={'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, hash='f7c1ab94daa56b335bf5f7b02337c9431c133a949f76c2e4c1c632fec1f3f6e4')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='## 4\\\\. Hoạt động Câu lạc bộ sinh viên.\\n\\nĐoàn Thanh niên trường là đơn vị chủ quản các Câu lạc bộ sinh viên, bên cạnh liên chi đoàn các Khoa. Tính đến năm học 2023-2024, toàn trường có 35 câu lạc bộ thuộc 3 nhóm: Học tập, Sở thích và Tình nguyện.\\n\\nNhóm các Câu lạc bộ học thuật: CLB Lý Luận Trẻ, CLB Lãnh đạo trẻ, CLB Marketing, CLB Kế toán, CLB Luật Kinh tế, CLB Một Sức Khoẻ, CLB Nghiên cứu khoa học Khoa Dược, CLB Sinh viên Kỹ thuật, CLB Tài Chính & Kinh Doanh, CLB Tiếng Anh, CLB tiếng Trung Quốc, CLB Khởi nghiệp Sáng tạo, CLB Nhân Lực, CLB Sinh viên Điều dưỡng, CLB Y Học, CLB Kinh doanh Quốc tế.\\n\\nNhóm các Câu lạc bộ sở thích: CLB Múa, CLB Âm nhạc, CLB Thể thao Điện tử, CLB Bóng rổ, CLB Truyền thông, CLB Truyền thông và Sự kiện, CLB văn hoá Nhật Bản Asaphe, CLB Võ thuật, CLB Sách và Hành động, CLB Karate-Do, CLB Bóng đá, CLB Hình Thể, CLB Bóng chuyền, CLB Thiên Nhiên.\\n\\nNhóm các Câu lạc bộ Tình nguyện: Đội Thanh niên Vận Động hiến máu (CLB Sắc Hồng Phenikaa), CLB Sinh viên Tình nguyện, CLB Sinh viên Thanh Hóa, CLB Sinh viên Nghệ Tĩnh, CLB sinh viên tình nguyện Khoa Tiếng Anh.\\n\\nTrong năm học 2023-2024, các Câu lạc bộ tại trường Đại học Phenikaa đã tổ chức hơn 487 hoạt động lớn nhỏ, từ cấp thành phố đến cấp đơn vị. Trong các hoạt động này, sinh viên Phenikaa đã thể hiện vai trò lãnh đạo, sự tích cực, chủ động và sáng tạo. Các hoạt động được tổ chức nhằm thắt chặt tinh thần đoàn kết, nâng cao năng lực học tập, nghiên cứu khoa học và phát triển kỹ năng mềm. Những nỗ lực này không chỉ đóng góp vào sự phát triển cá nhân của từng sinh viên mà còn góp phần xây dựng môi trường học tập và hoạt động phong phú, đa dạng và hiệu quả', mimetype='text/plain', start_char_idx=101393, end_char_idx=103036, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5815917050427712), NodeWithScore(node=TextNode(id_='1b0b4b1c-f2b2-4d32-b3e0-e8d294d839f7', embedding=None, metadata={'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='80ae3218-f083-48a4-aff9-c3e81e4fd2a9', node_type='4', metadata={'filename': 'sotay.md', 'extension': '.md'}, hash='435de79ca1d20618b2c86e11a7573a678269e32b107969df99a709e89da8ea19'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='56762154-7c55-485a-8bd2-a89d3c77372b', node_type='1', metadata={'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, hash='89f0abdfd76987cd82d0b9ee03eb526fc8d5a17a68bf0eec0aab18fbd84939b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='379c9ce5-163c-4ae2-bdb7-e130b8eb93c8', node_type='1', metadata={'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, hash='3188a03c20435271a3dd85c4ce4bc738c94561aaa8443641df2846bf16480517')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='## 5\\\\. Phong trào thể dục thể thao.\\n\\nXuyên suốt năm học, Đoàn Thanh niên trường Đại học Phenikaa không ngừng tổ chức và phối hợp tổ chức nhiều hoạt động thể dục thể thao sôi nổi và đa dạng. Những hoạt động này không chỉ nhằm nâng cao sức khỏe mà còn tạo sân chơi bổ ích, góp phần xây dựng tinh thần đoàn kết, giao lưu học hỏi giữa các bạn sinh viên. Các phong trào thể dục thể thao nổi bật bao gồm:\\n\\n\\\\- Giải Futsal Sinh viên Miền Bắc và Giải Futsal Sinh viên toàn quốc: Đoàn Thanh niên trường tự hào đăng cai tổ chức hai giải đấu uy tín này trong các năm 2023 và 2024. Giải đấu đã thu hút hàng trăm đội bóng từ khắp nơi tham gia, tạo nên một sân chơi cạnh tranh lành mạnh và đầy kịch tính. Đặc biệt, đội tuyển Futsal Trường Đại học Phenikaa đã xuất sắc thi đấu và liên tiếp vào đến Chung kết toàn quốc trong cả hai năm, thể hiện tinh thần thể thao mạnh mẽ và sự đoàn kết của các thành viên.\\n\\n\\\\- Giải thi đấu thể thao Sinh viên Phenikaa: Đây là sự kiện thể thao sinh viên lớn nhất của trường, được tổ chức hằng năm với sự tham gia đông đảo của sinh viên. Hội thao bao gồm nhiều môn thi đấu phong phú như bóng đá, bóng rổ, bóng chuyền, cầu lông, điền kinh, thể thao điện tử, cờ caro người, vũ đạo, và nhiều môn khác. Hội thao không chỉ là nơi để sinh viên thể hiện tài năng và đam mê thể thao mà còn là dịp để rèn luyện sức khỏe, phát triển kỹ năng cá nhân và gắn kết tinh thần đồng đội.\\n\\n\\\\- Các giải thể thao cấp Liên chi đoàn và cấp Câu lạc bộ: Ngoài các giải đấu lớn, Đoàn Thanh niên trường còn tổ chức nhiều giải thể thao cấp Liên chi đoàn và cấp Câu lạc bộ diễn ra quanh năm. Các môn thể thao như cầu lông, tennis, bóng rổ, bóng chuyền, và bóng đá đều được tổ chức thường xuyên, thu hút sự tham gia của đông đảo sinh viên. Những giải đấu này không chỉ tạo cơ hội cho sinh viên rèn luyện thể lực mà còn giúp xây dựng tình bạn, tinh thần đồng đội và sự tự tin trong mỗi cá nhân.\\n\\nNhững phong trào thể dục thể thao tại trường Đại học Phenikaa không chỉ là hoạt động ngoại khóa bổ ích mà còn là một phần không thể thiếu trong hành trình học tập và phát triển toàn diện của sinh viên. Tham gia các hoạt động này, sinh viên sẽ có cơ hội rèn luyện bản thân, khám phá khả năng tiềm ẩn, và tạo dựng những kỷ niệm đáng nhớ trong thời gian học tập tại trường.', mimetype='text/plain', start_char_idx=103039, end_char_idx=105290, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.48874381815563667)], metadata={'56762154-7c55-485a-8bd2-a89d3c77372b': {'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}, '1b0b4b1c-f2b2-4d32-b3e0-e8d294d839f7': {'filename': 'sotay.md', 'extension': '.md', 'header_path': '/PHẦN II: CÔNG TÁC PHÁT TRIỂN ĐẢNG VÀ PHONG TRÀO SINH VIÊN/'}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "a = [-0.025781047,-0.033937745,-0.0035234164,-0.006522394,0.06374869,-0.017967975,0.017474934,-0.01022034,0.021461274,0.023524266,0.020245433,0.03454678,-0.016306609,0.014291614,0.016947657,-0.06881209,0.018\n",
    "29737,-0.007659844,-0.070655756,0.0080021825,-0.019873174,-0.020131433,0.035891127,0.027568502,0.015041954,-0.05870153,-0.01921712,0.0006242894,0.0045211706,-0.013498516,-0.0044600796,0.006067629,-0.01428\n",
    "3615,0.04108276,0.013717515,-0.0042053456,0.018243123,0.026556639,0.00588415,0.05823155,0.09535303,0.027025497,-0.016788077,-0.02896301,-0.05800394,-0.05139652,-0.030882189,-0.0055639963,0.040094074,0.010\n",
    "146199,0.0155335395,-0.033512816,-0.011116678,-0.008316473,-0.020050649,-0.03617542,-0.018893618,-0.035207026,0.021612382,0.063098945,0.011948381,-0.008323196,0.0037073942,-0.023090852,0.034248024,-0.0335\n",
    "95495,0.06826163,-0.02362298,-0.04622761,0.014586989,0.09337702,4.3676617e-05,-0.009302836,0.06318578,0.0058742315,0.0049211844,-0.01293869,-0.04828144,0.0076954737,-0.003931434,0.09249732,-0.0636658,-0.0\n",
    "29506188,0.010345276,-0.0037266717,0.05692828,-0.0009247474,0.023830041,-0.031218452,-0.008897523,0.02167126,0.038075253,-0.014139366,-0.004734438,0.047494955,0.006201947,0.013472391,-0.008914902,0.024016\n",
    "323,-0.018737586,0.026377428,-0.002310049,0.03411891,0.050672084,-0.03635302,0.07576832,-0.010015942,0.0420857,0.06510202,0.03443908,0.0050171097,0.006755395,-0.010610361,0.015074633,-0.015741484,-0.01004\n",
    "2277,0.04704416,0.038340896,0.0717939,0.0030486041,0.07642474,-0.010639381,-0.0037810663,-0.022865081,-0.012294439,0.05219033,0.011470987,0.01676328,-0.02670609,0.11601509,-0.005238634,0.014336815,0.00844\n",
    "2568,0.016542066,0.0065178685,0.012898413,0.032911588,-0.059196014,-0.00097169814,-0.056094922,0.012969295,0.013740671,-0.019528901,0.053142626,-0.02382017,-0.011689029,-0.022471124,-0.03038406,0.00227095\n",
    "44,0.038065013,-0.014193208,-0.023760539,-0.058398526,0.028567215,-0.021201555,0.042063523,-0.03586321,-0.042326998,-0.02500024,0.055182975,0.0055531366,-0.0061869253,-0.036054194,0.012158398,0.054249674,\n",
    "0.020443847,0.08203715,-0.028484743,-0.046000447,0.008142642,-0.10488461,0.02215282,0.024497887,0.11238595,-0.012398157,0.04696001,0.03654584,-0.09105486,0.0044325655,-0.061519433,-0.03704975,-0.10167536,\n",
    "0.035291433,-0.0070225024,-0.034130517,0.03725949,-0.083246775,0.036304563,0.023630314,0.024090877,0.0060117356,0.022873146,-0.051978562,0.00083908375,0.030981021,0.02786017,0.03460223,0.05990838,0.015919\n",
    "255,0.0001456396,0.017250769,2.4476503e-05,0.073227696,-0.0007080996,0.015816052,-0.015610662,0.023080427,-0.00021706491,-0.01755867,0.049456276,0.038523305,0.018470932,0.020029647,0.0070857825,0.00358479\n",
    "21,-0.05043734,0.013776756,-0.0034042785,0.023913039,0.029486053,0.0148019865,0.029721739,-0.028781857,0.032252867,-0.07794797,-0.00441391,0.009065401,0.004390283,-0.01904825,0.0018503732,0.024611084,0.02\n",
    "3565928,0.031089298,0.035709888,0.04475233,-0.0055951,0.022036666,0.0649513,0.02039277,-0.029415833,0.021660285,-0.04148905,-0.025361804,0.0025457172,0.052602574,-0.004715528,-0.016605046,0.020173064,0.056383256,-0.028832437,0.060502946,-0.001315043,-0.043994483,0.03652105,0.0011176751,0.09411239,-0.020758366,-0.015107583,0.0972184,-0.024726667,-0.022166062,-0.031599823,-0.049214378,-0.018678555,0.011023883,0.013329763,0.004013698,0.0011662851,0.00560056,0.00084105326,-0.002567025,0.028064448,-0.035679433,-0.03052075,-0.0056540053,0.06461837,0.02826543,0.034408577,-0.03580707,0.01423031,-0.015575099,0.0020048874,-0.016601656,0.013817751,0.016433856,0.014412406,0.024280958,-0.09431619,-0.054674704,0.018965095,-0.026086733,-0.023032552,0.027269917,0.0015002127,0.016640455,0.03591621,0.031548377,0.014553873,0.001261748,-0.041424617,0.062686875,-0.018430091,0.0344192,-0.0035707122,-0.040988162,0.014467037,0.030434946,0.0014247083,0.026420437,-0.04764906,-0.010776579,-0.012547868,0.021940732,0.038261697,-0.030288342,0.04408246,0.06952078,-0.002093903,0.029144052,0.03619782,0.00046032964,0.0030994874,0.02805743,-0.032307386,-0.042379133,-0.11076065,-0.018509187,-0.03283999,0.051099584,-0.028670266,0.014084399,0.022443691,0.005736354,0.0050931494,-0.029565213,-0.016503325,-0.0072058667,0.045532554,-0.009587285,-0.0007503008,-0.009568805,0.020038195,-0.023130992,0.042177998,0.062119696,0.026870463,-0.0638148,0.029426431,0.047253903,0.013163639,0.022799386,0.0169884,-0.0033186146,-0.009073625,-0.03315478,-0.021802485,0.055233765,-0.053881917,-0.022277905,0.023777887,0.045172144,-0.062077075,-0.06175907,-0.03297029,0.042635966,-0.011382758,-0.021761112,0.04740773,-0.02654179,0.0021823072,-0.01925299,-0.03965091,-0.033291955,0.01193374,0.034874536,0.021795103,0.016804967,0.003987016,-0.06564052,0.03311134,-0.0063024745,0.023470731,0.093714654,-0.0062988508,0.014498067,0.013785323,-0.013296816,-0.00941637,0.1385098,-0.0118819,0.0068906685,-0.049695443,-0.023742314,-0.026848935,-0.018409833,-0.012689785,0.053461548,-0.011136327,-0.01765711,0.0039448077,-0.015192648,0.008486739,-0.0031780372,0.01651246,0.02459523,-0.026043044,0.04586137,0.008531233,0.0058803605,0.021685958,0.0230622,0.06409236,-0.014271233,-0.015255288,-0.07674667,0.009009791,-0.045812313,0.005182377,-0.010701265,-0.09428562,0.050312147,-0.01359953,0.02727839,0.0104972245,0.009077621,-0.0069864327,0.028328834,-0.041523,-0.010253087,-0.006989681,0.03169574,-0.028131988,-0.044665966,0.037890624,0.043179084,-0.016721416,-0.050134633,-0.09309647,0.0443552,-0.013217126,-0.025385262,0.019326402,0.03046167,0.0032809202,0.020077376,0.08425279,-0.03152557,-0.027979665,-0.040828254,0.041023962,0.010451386,-0.049757037,-0.06389521,0.04577775,0.11032759,-0.01478715,-0.0013123329,-0.0057449644,-0.056096382,0.019300485,-0.057047077,0.09613127,-0.08470314,-0.002538291,0.012050392,-0.020466056,0.0018428765,0.015957821,0.010045454,-0.027464947,-0.05304387,-0.0017189081,-0.00044683993,0.07399609,-0.03355699,-0.022432676,0.0038787543,-0.07696227,0.077597946,0.012570026,0.07203425,0.100889206,-0.0023537297,-0.11677667,-0.006296433,-0.039252225,-0.020701569,0.013480911,-0.016674846,-0.049486697,0.01578075,-0.010221555,0.0056604287,0.0030853504,-0.014291335,-0.024156936,0.017458318,-0.025323585,-0.05071824,-0.032485902,-0.00034597734,-0.005264533,0.010059221,-0.05132048,-0.029029183,0.027546214,-0.019646268,-0.014226471,-0.020461889,-0.02869489,0.03339299,0.0059693875,0.0071957936,-0.052447677,-0.016999353,0.035590753,-0.009186814,0.08643675,0.009917695,-0.02835672,-0.023783546,-0.0092338305,0.02696319,-0.057907265,-0.04862955,0.06230766,-0.0060877884,0.016903888,-0.0589624,0.023283437,0.053831432,-0.044943117,0.049496733,0.016155738,-0.008993564,-0.020008856,-0.019489605,-0.009891051,-0.03076619,0.03745964,-0.012285526,-0.006464071,-0.03158925,-0.016418217,0.0045060916,0.0044829953,-0.016416283,-0.022432407,-0.021309067,-0.040153798,0.0017244071,-0.011144686,-0.014466942,0.000987088,0.029321868,-0.019044623,-0.0075357845,-0.02778883,-0.0027804621,-0.057043083,-0.015300382,-0.015146936,-0.018516395,0.012854523,-0.064294405,-0.039049532,-0.010433514,-0.0138535695,0.015720557,0.0067423405,0.011377223,-0.008299245,-0.022827405,0.022584245,0.008422162,-0.026264476,-0.011084469,0.013873163,0.029553458,0.117781185,-0.009252481,0.033332262,0.016009113,-0.035041902,-0.0031638932,-0.014896066,0.00011788619,0.007432344,0.0014426325,-0.046635125,-0.01815657,-0.04462222,-0.005605969,-0.036327798,-0.0015648665,-0.008607245,-0.032616172,0.042430308,0.023759468,0.02233292,0.027678058,-0.02785335,-0.014189835,-0.010979297,-0.033582345,0.034804434,-0.08577874,0.0035472668,0.04735591,0.0210929,0.024103327,-0.08535031,0.0006667063,0.0434777,-0.013046924,0.012597097,0.025504794,0.032170646,0.014775667,0.015759682,-0.008823055,-0.049017325,0.035210487,0.04622099,0.024660252,0.056829926,0.024212662,-0.005533401,0.06236463,-0.03310204,-0.06560316,0.011319459,-0.014701335,-0.031457387,0.059012365,0.04706094,-0.012730672,-0.004863598,-0.015711727,-0.014779339,-0.045150284,0.011784847,-0.02279314,0.01561628,-0.035316627,-0.0069257333,-0.07430056,-0.040022258,-0.036295578,-0.037415996,-0.00043382862,0.063963786,-0.0442006,0.019720355,-0.008657636,0.022111269,-0.08446134,-0.012476086,-0.036475476,-0.00754599,-0.028372182,-0.0008406683,-0.06552756,0.020239554,-0.027355889,-0.008206986,-0.0062923213,0.019368757,0.04243642,-0.021083457,0.003370888,0.0039641657,0.0069006565,0.040772073,0.034401573,0.02600415,-0.0074081416,0.037342828,0.018760048,-0.016043628,-0.024304086,0.017079575,-0.01733274,0.07690393,0.041597772,-0.028011495,0.011646621,0.0077147395,0.00889746,-0.054256495,0.10787696,0.039593164,0.038694844,0.019692332,-0.038265478,-0.034334905,-0.009120436,-0.022154331,-0.034263656,0.010911191,-0.054532792,-0.031675607,0.014509436,-0.010880917,-0.016382195,-0.046661276,-0.006406399,-0.06947653,-0.01569205,-0.0031113962,0.059528876,0.016208854,-0.015155383,0.0037046268,0.053111646,0.029711934,0.01852671,0.013081114,0.046932895,0.01362364,0.007682404,0.01638359,-0.0033168409,-0.020576926,-0.02994545,-0.04090787,0.0023254692,0.013215864,0.0069828564,-0.019535288,-0.05870297,0.020121222,-0.06947073,0.02794181,0.035357755,0.004650945,-0.0078039984,-0.028969742,0.013774722,0.04583847,-0.06869922,0.026563806,0.028046366,-0.012515769,-0.01964625,-0.003701257,0.0099070035,0.014287385,-0.06183862,0.016796658,0.005291896,-0.022570133,-0.05927856,0.024811644,0.015023561,0.027111113,-0.03710855,-0.011503585,-0.036736224,0.020275647,-0.07782149,-0.04183767,-0.011588072,0.021162579,-0.005347005,0.0049633593,0.0028254658,-0.0016790349]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.split(','))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNssVBLTl0Bo6C/jiGR36AP",
   "gpuType": "T4",
   "mount_file_id": "1vn34NiOBBzi4s6DLfG5vr1Rh6LjgWXcZ",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "datn",
   "language": "python",
   "name": "datn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d28d7bf93cd48a6857cdf90573d5079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_757529f35dd348a2b22444fb55d87e9b",
      "placeholder": "​",
      "style": "IPY_MODEL_b4c50c39e6654a75a46cd89b2c1cc941",
      "value": " 14.5M/14.5M [00:01&lt;00:00, 10.9MB/s]"
     }
    },
    "39c00b344ed14cd3a244b186cdd2c81e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4074586a692f48bdb29b74cea3fe8a28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "553add784af14355a5e5de7ddd32bb4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6248fe51cb8e44e985d58422c0ece076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c3580f8ee0547fd9ab8342695997313",
       "IPY_MODEL_c1d1df4b658f4a45b9e6f4c17e0e1697",
       "IPY_MODEL_1d28d7bf93cd48a6857cdf90573d5079"
      ],
      "layout": "IPY_MODEL_39c00b344ed14cd3a244b186cdd2c81e"
     }
    },
    "74fd9541b9e34caebe8b14275cf69729": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "757529f35dd348a2b22444fb55d87e9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c3580f8ee0547fd9ab8342695997313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_553add784af14355a5e5de7ddd32bb4f",
      "placeholder": "​",
      "style": "IPY_MODEL_4074586a692f48bdb29b74cea3fe8a28",
      "value": "tokenizer.json: 100%"
     }
    },
    "b13a54266e194d618d5aa71c7a675170": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4c50c39e6654a75a46cd89b2c1cc941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1d1df4b658f4a45b9e6f4c17e0e1697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74fd9541b9e34caebe8b14275cf69729",
      "max": 14500438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b13a54266e194d618d5aa71c7a675170",
      "value": 14500438
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
